{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17d05ef8",
   "metadata": {},
   "source": [
    "# TRAFFIC SIGNS CLASSIFICATION USING LE-NET ARCHITECTURE IN KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d6d03b",
   "metadata": {},
   "source": [
    "## IMPORT LIBRARIES AND DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95c50e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64ab736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f6459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open(\"./traffic-signs-data/train.p\", mode='rb') as training_data:\n",
    "    train = pickle.load(training_data)\n",
    "with open(\"./traffic-signs-data/valid.p\", mode='rb') as validation_data:\n",
    "    valid = pickle.load(validation_data)\n",
    "with open(\"./traffic-signs-data/test.p\", mode='rb') as testing_data:\n",
    "    test = pickle.load(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0f7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train['features'], train['labels']\n",
    "X_validation, y_validation = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb0068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28e966d",
   "metadata": {},
   "source": [
    "### Single Image View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1457a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = int(input())\n",
    "plt.imshow(X_train[i]) # Show images are not shuffled\n",
    "y_train[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f1f6e8",
   "metadata": {},
   "source": [
    "### DATA PEPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce44103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to grayscale\n",
    "X_train_gray = np.sum(X_train / 3, axis=3, keepdims=True)\n",
    "X_test_gray = np.sum(X_test / 3, axis=3, keepdims=True)\n",
    "X_validation_gray = np.sum(X_validation / 3, axis=3, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257fab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images\n",
    "X_train_gray_norm = (X_train_gray - 128) / 128\n",
    "X_test_gray_norm = (X_test_gray - 128) / 128\n",
    "X_validation_gray_norm = (X_validation_gray - 128) / 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7918dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1743ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = int(input())\n",
    "plt.imshow(X_train_gray[i].squeeze(), cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(X_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d37df38",
   "metadata": {},
   "source": [
    "### MODEL TRAINING\n",
    "The model consists of the following layers:\n",
    "\n",
    "STEP 1: THE FIRST CONVOLUTIONAL LAYER #1\n",
    "\n",
    "Input = 32x32x1\n",
    "Output = 28x28x6\n",
    "Output = (Input-filter+1)/Stride* => (32-5+1)/1=28\n",
    "Used a 5x5 Filter with input depth of 3 and output depth of 6\n",
    "Apply a RELU Activation function to the output\n",
    "pooling for input, Input = 28x28x6 and Output = 14x14x6\n",
    "Stride is the amount by which the kernel is shifted when the kernel is passed over the image.\n",
    "\n",
    "\n",
    "STEP 2: THE SECOND CONVOLUTIONAL LAYER #2\n",
    "\n",
    "Input = 14x14x6\n",
    "Output = 10x10x16\n",
    "Layer 2: Convolutional layer with Output = 10x10x16\n",
    "Output = (Input-filter+1)/strides => 10 = 14-5+1/1\n",
    "Apply a RELU Activation function to the output\n",
    "Pooling with Input = 10x10x16 and Output = 5x5x16\n",
    "\n",
    "\n",
    "STEP 3: FLATTENING THE NETWORK\n",
    "\n",
    "Flatten the network with Input = 5x5x16 and Output = 400\n",
    "\n",
    "\n",
    "STEP 4: FULLY CONNECTED LAYER\n",
    "\n",
    "Layer 3: Fully Connected layer with Input = 400 and Output = 120\n",
    "Apply a RELU Activation function to the output\n",
    "\n",
    "\n",
    "STEP 5: ANOTHER FULLY CONNECTED LAYER\n",
    "\n",
    "Layer 4: Fully Connected Layer with Input = 120 and Output = 84\n",
    "Apply a RELU Activation function to the output\n",
    "\n",
    "\n",
    "STEP 6: FULLY CONNECTED LAYER\n",
    "\n",
    "Layer 5: Fully Connected layer with Input = 84 and Output = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a83c11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = X_train_gray[i].shape\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e287c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=num_classes)\n",
    "y_validation_one_hot = to_categorical(y_validation, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4958ce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LeNet model\n",
    "cnn_model = Sequential()\n",
    "\n",
    "cnn_model.add(Conv2D(filters=6, kernel_size=(5, 5), activation='relu', input_shape=(32, 32, 1)))\n",
    "cnn_model.add(AveragePooling2D())\n",
    "\n",
    "cnn_model.add(Conv2D(filters=16, kernel_size=(5, 5), activation='relu'))\n",
    "cnn_model.add(AveragePooling2D())\n",
    "\n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "cnn_model.add(Dense(units=120, activation='relu'))\n",
    "\n",
    "cnn_model.add(Dense(units=84, activation='relu'))\n",
    "\n",
    "cnn_model.add(Dense(units=43, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df40d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7d623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can train the model\n",
    "cnn_model.fit(X_train_gray_norm,\n",
    "              y_train,\n",
    "              batch_size=500,\n",
    "              epochs=5,\n",
    "              verbose=1,\n",
    "              validation_data=(X_validation_gray_norm, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a09f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ede00be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = cnn_model.fit(X_train_gray_norm, y_train, batch_size=500, epochs=50, verbose=1,\n",
    "                        validation_data=(X_validation_gray_norm, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37333ed1",
   "metadata": {},
   "source": [
    "### MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7c0bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "score = cnn_model.evaluate(X_test_gray_norm, y_test, verbose=0)\n",
    "print('Test Accuracy: {:.4f}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b148c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a71e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1149036",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d71674",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'ro', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f123671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "predicted_classes = cnn_model.predict(X_test_gray_norm)\n",
    "cm = confusion_matrix(y_test, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95993926",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79700bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 10\n",
    "W = 10\n",
    "fig, axes = plt.subplots(L, W, figsize = (12,12))\n",
    "axes = axes.ravel() # \n",
    "\n",
    "for i in np.arange(0, L * W):  \n",
    "    axes[i].imshow(X_test[i])\n",
    "#     axes[i].set_title(\"Prediction={}\\n True={}\".format(predicted_classes[i], y_true[i]))\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.subplots_adjust(wspace=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
